{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "AlexNet est un modèle de réseau neuronal convolutionnel classique, qui c'est illustré en 2012 lors du concours ImageNet de reconnaissance d'images\n",
    "\n",
    "AlexNet a remporté le défi de reconnaissance visuelle à grande échelle ImageNet (ILSVRC) en 2012 avec un taux d’erreur top-5 de 15,3%\n",
    "\n",
    "\n",
    "AlexNet est généralement utilisé pour la classification d’images. Le réseau pré-entraîné peut classer les images en 1000 catégories d’objets. Il a été formé sur plus d’un million d’images de la base de données ImageNet.\n",
    "\n",
    "\n",
    "## Caractéristique\n",
    "\n",
    "- *Architecture* : AlexNet est composé de 8 couches avec des paramètres apprenables1. Il comprend 5 couches de convolution, chacune suivie d’une couche de max pooling, puis 3 couches entièrement connectées.\n",
    "\n",
    "\n",
    "- *Fonction d’activation* : AlexNet utilise la fonction d’activation ReLU au lieu de tanh ou sigmoid, ce qui a permis d’accélérer le temps d’entraînement jusqu’à 6 fois tout en conservant la même précision.\n",
    "\n",
    "\n",
    "- *Prévention du surajustement* : Comme le modèle devait être formé sur 60 millions de paramètres, il était sujet au surajustement. L’utilisation de Dropout et de l’augmentation des données a considérablement aidé à réduire le surajustement.\n",
    "\n",
    "\n",
    "- *Convolution groupée* : Les convolutions groupées sont utilisées pour adapter le modèle sur deux GPU4.\n",
    "\n",
    "\n",
    "- *Normalisation de la réponse locale* : AlexNet utilise la normalisation de la réponse locale, qui est une technique de normalisation appliquée après la fonction d’activation2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple\n",
    "\n",
    "Seul un exemple avec pytorch sera présenté ici. Tensorflow n'a pas de modele préentrainé pour AlexNet, parce que l'architecture est trés similaire a celle de VGGNet (que vous pouvez retrouver [**ici**](./vggnet.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/miniconda3/envs/ai-explorer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/miniconda3/envs/ai-explorer/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ben/miniconda3/envs/ai-explorer/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/ben/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:30<00:00, 8.15MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.alexnet(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../assets/car.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "input_tensor = preprocess(img)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction: sports car\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "\n",
    "with open('../assets/imagenet_classes.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print('Prédiction:', classes[predicted_idx.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quand utiliser AlexNet\n",
    "\n",
    "AlexNet est particulièrement utile lorsque vous devez former un modèle sur un grand nombre de paramètres. Par exemple, le modèle AlexNet a dû être formé sur 60 millions de paramètres. Cependant, il était sujet au surajustement. Selon son article de recherche, l’utilisation de Dropout et de l’augmentation des données a considérablement aidé à réduire le surajustement.\n",
    "\n",
    "Il est utilisé pour:\n",
    "\n",
    "- Vous travaillez sur un problème de classification d’images.\n",
    "- Vous avez une grande quantité de données et de nombreux paramètres à entraîner.\n",
    "- Vous pouvez gérer le risque de surajustement avec des techniques comme le dropout et l’augmentation des données.\n",
    "\n",
    "\n",
    "Il est important de noter que bien qu’AlexNet ait été une avancée significative dans le domaine de l’apprentissage profond, de nombreux modèles plus récents et plus performants ont été développés depuis. Par conséquent, bien qu’AlexNet puisse toujours être utilisé pour certaines tâches, il existe souvent de meilleures options disponibles pour la plupart des applications modernes de vision par ordinateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
